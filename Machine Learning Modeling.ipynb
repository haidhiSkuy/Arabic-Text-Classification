{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Text Classification\n",
    "coded by: Haidhi Angkawijana Tedja <br>\n",
    "email : haidhiangkawijana@gmail.com\n",
    "\n",
    "In this project I did some experiment with several vectorization method such as TF-IDF, CountVectorized, and word2vec. The final result is word2vec not good enough if we use classic machine learning as model, but it's good enough if we use it with neural network like LSTM, RNN, etc. Decision tree also isn't good enough for text classification task, due to it's disadvantages *Curse of dimensionality*\n",
    "\n",
    "The datasets I used:\n",
    "1. SANAD : Single-label Arabic News Articles Dataset\r\n",
    "2. HARD : hotel reviews in Arabic language\r\n",
    "3. OCLAR : Opinion Corpus for Lebanese Arabic Reviews\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omSFdL6mQxg6"
   },
   "source": [
    "# Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MGz4cqmtPRA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.02 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ShoVV3KQ0Ro"
   },
   "source": [
    "# FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RPmIjSjnzypE"
   },
   "outputs": [],
   "source": [
    "#using base model only\n",
    "def baseModelOnly(Xtrain,Xtest,ytrain,ytest, includeNB=True):\n",
    "  logreg = LogisticRegression()\n",
    "  logreg.fit(Xtrain, ytrain)\n",
    "  logreg_acc = accuracy_score(ytest,logreg.predict(Xtest))\n",
    "\n",
    "  svm = LinearSVC()\n",
    "  svm.fit(Xtrain, ytrain)\n",
    "  svm_acc = accuracy_score(ytest,svm.predict(Xtest))\n",
    "\n",
    "  dt = DecisionTreeClassifier()\n",
    "  dt.fit(Xtrain, ytrain)\n",
    "  dt_acc = accuracy_score(ytest,dt.predict(Xtest))\n",
    "\n",
    "  final_result = [logreg_acc,svm_acc,dt_acc]\n",
    "\n",
    "  if includeNB == True:\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(Xtrain, ytrain)\n",
    "    nb_acc = accuracy_score(ytest,nb.predict(Xtest))\n",
    "    final_result.append(nb_acc)\n",
    "\n",
    "  return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TwQS8TYHetbF"
   },
   "outputs": [],
   "source": [
    "def make_corpus(data_series):\n",
    "  word_list = data_series.apply(lambda x: x.split())\n",
    "  corpus = []\n",
    "  for i in word_list:\n",
    "    corpus.append(i)\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gHhr7vj2PMjE"
   },
   "outputs": [],
   "source": [
    "def sentence2vectorSum(text, model, aggregate='sum'):\n",
    "  text = text.split()\n",
    "  sentence_vector = []\n",
    "  for word in text:\n",
    "    if word in model.wv.key_to_index:\n",
    "      sentence_vector.append(model.wv[word])\n",
    "\n",
    "  if sentence_vector != []:\n",
    "    len_of_vector = len(sentence_vector[0])\n",
    "    matrics = np.array(sentence_vector)\n",
    "    max_vector = []\n",
    "    min_vector = []\n",
    "    average_vector = []\n",
    "    sum_vector = []\n",
    "    for num in range(0,len_of_vector):\n",
    "        max_vector.append(max(matrics[:, num]))\n",
    "        min_vector.append(min(matrics[:, num]))\n",
    "        average_vector.append(np.mean(matrics[:, num]))\n",
    "        sum_vector.append(np.sum(matrics[:, num]))\n",
    "\n",
    "    if aggregate == 'sum':\n",
    "        return max_vector\n",
    "    elif aggregate == 'average':\n",
    "        return average_vector\n",
    "    elif aggregate == 'max':\n",
    "        return max_vector\n",
    "    elif aggregate == 'min':\n",
    "        return min_vector\n",
    "\n",
    "  else:\n",
    "    VECTOR_SIZE = model.vector_size\n",
    "    return np.array([0 for i in range(0,VECTOR_SIZE+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mcnc-I4Q140"
   },
   "source": [
    "# OCLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "dKfP345NPTF4",
    "outputId": "54d11f80-0855-43d1-ea3a-6e0cf98dff81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Label : 5\n",
      "3895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هذا الفندق ينقصه بعض الاشياء داخل الغرف مثلا ع...</td>\n",
       "      <td>2</td>\n",
       "      <td>ندق نقص شيء دخل غرف ثلا وضح قنو تلفزيونية عطل ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لطيف ولكن الغرف الفندقية تحتاج صيانة كادر الخد...</td>\n",
       "      <td>4</td>\n",
       "      <td>لطف غرف ندق حاج صين كدر خدم يجب ستى طلب</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مكان جميل جدا وحسن الخلق والضيافه</td>\n",
       "      <td>5</td>\n",
       "      <td>جمل وحس خلق ضيف</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بحاجة الى اعادة تأهيل للمفروشات</td>\n",
       "      <td>3</td>\n",
       "      <td>بحج أهل فرش</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>فندق ممتاز ومعاملة راقية جدا</td>\n",
       "      <td>5</td>\n",
       "      <td>ندق متز عمل رقي</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  هذا الفندق ينقصه بعض الاشياء داخل الغرف مثلا ع...       2   \n",
       "1  لطيف ولكن الغرف الفندقية تحتاج صيانة كادر الخد...       4   \n",
       "2                  مكان جميل جدا وحسن الخلق والضيافه       5   \n",
       "3                    بحاجة الى اعادة تأهيل للمفروشات       3   \n",
       "4                       فندق ممتاز ومعاملة راقية جدا       5   \n",
       "\n",
       "                                               clean  category_encoded  \n",
       "0  ندق نقص شيء دخل غرف ثلا وضح قنو تلفزيونية عطل ...                 1  \n",
       "1            لطف غرف ندق حاج صين كدر خدم يجب ستى طلب                 3  \n",
       "2                                    جمل وحس خلق ضيف                 4  \n",
       "3                                        بحج أهل فرش                 2  \n",
       "4                                    ندق متز عمل رقي                 4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"OCLAR_CLEAN.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "df['category_encoded'] = df['rating']-1\n",
    "df['category_encoded'].unique()\n",
    "\n",
    "print(f\"Jumlah Label : {len(df['rating'].unique())}\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h-eEIh5d1An1"
   },
   "outputs": [],
   "source": [
    "X = df['clean']\n",
    "y = df['category_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Q7K5FiVM06iP",
    "outputId": "b43ed5fb-bc70-4c08-f747-9464ecc9cd31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de010_row0_col0, #T_de010_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de010_row1_col0 {\n",
       "  background-color: #218944;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de010_row1_col1 {\n",
       "  background-color: #4bb062;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de010_row2_col0, #T_de010_row2_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de010_row3_col0 {\n",
       "  background-color: #37a055;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de010_row3_col1 {\n",
       "  background-color: #1a843f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de010_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >TFIDF</th>\n",
       "      <th class=\"col_heading level0 col1\" >CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de010_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_de010_row0_col0\" class=\"data row0 col0\" >0.617458</td>\n",
       "      <td id=\"T_de010_row0_col1\" class=\"data row0 col1\" >0.621309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de010_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_de010_row1_col0\" class=\"data row1 col0\" >0.599487</td>\n",
       "      <td id=\"T_de010_row1_col1\" class=\"data row1 col1\" >0.598203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de010_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_de010_row2_col0\" class=\"data row2 col0\" >0.544288</td>\n",
       "      <td id=\"T_de010_row2_col1\" class=\"data row2 col1\" >0.563543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de010_level0_row3\" class=\"row_heading level0 row3\" >NB</th>\n",
       "      <td id=\"T_de010_row3_col0\" class=\"data row3 col0\" >0.593068</td>\n",
       "      <td id=\"T_de010_row3_col1\" class=\"data row3 col1\" >0.608472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22daf4c2320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_idf = tfidf.fit_transform(X_train)\n",
    "X_test_idf = tfidf.transform(X_test)\n",
    "\n",
    "#count vectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "tfidf_clf = baseModelOnly(X_train_idf,X_test_idf,y_train,y_test)\n",
    "cv_clf = baseModelOnly(X_train_cv,X_test_cv,y_train,y_test)\n",
    "\n",
    "oclar_base_model_result = pd.DataFrame({'TFIDF':tfidf_clf,'CV':cv_clf})\n",
    "oclar_base_model_result.index = ['Logreg','SVM','Decision Tree','NB']\n",
    "oclar_base_model_result.style.background_gradient(cmap ='Greens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mT7N5eZ_ym2"
   },
   "source": [
    "## OCLAR Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RgOlj4a_0kJ",
    "outputId": "7fb85dd7-2306-48d7-e539-3d4f57995439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LEN : 227\n"
     ]
    }
   ],
   "source": [
    "oclar_corpus = make_corpus(df.clean)\n",
    "max_len = max([len(sentence) for sentence in oclar_corpus])\n",
    "print('MAX LEN : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0YWhPqK_4aa",
    "outputId": "3b450335-d37e-4d96-e9e7-40ea99f818a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78553, 695910)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_oclar = Word2Vec(min_count=10,window=15,sample=6e-5,alpha=0.03,min_alpha=0.0007,negative=25)\n",
    "w2v_oclar.build_vocab(oclar_corpus, progress_per=10000)\n",
    "w2v_oclar.train(oclar_corpus, total_examples=w2v_oclar.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "3d4iaWM8PRTw",
    "outputId": "dd76250b-17af-4699-84cf-cea502ebfd59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_efc16_row0_col0, #T_efc16_row0_col1, #T_efc16_row0_col2, #T_efc16_row0_col3, #T_efc16_row1_col0, #T_efc16_row1_col1, #T_efc16_row1_col2, #T_efc16_row1_col3 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efc16_row2_col0, #T_efc16_row2_col1, #T_efc16_row2_col2, #T_efc16_row2_col3 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_efc16_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >min</th>\n",
       "      <th class=\"col_heading level0 col1\" >max</th>\n",
       "      <th class=\"col_heading level0 col2\" >sum</th>\n",
       "      <th class=\"col_heading level0 col3\" >average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_efc16_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_efc16_row0_col0\" class=\"data row0 col0\" >0.620026</td>\n",
       "      <td id=\"T_efc16_row0_col1\" class=\"data row0 col1\" >0.582798</td>\n",
       "      <td id=\"T_efc16_row0_col2\" class=\"data row0 col2\" >0.578947</td>\n",
       "      <td id=\"T_efc16_row0_col3\" class=\"data row0 col3\" >0.577664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efc16_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_efc16_row1_col0\" class=\"data row1 col0\" >0.620026</td>\n",
       "      <td id=\"T_efc16_row1_col1\" class=\"data row1 col1\" >0.582798</td>\n",
       "      <td id=\"T_efc16_row1_col2\" class=\"data row1 col2\" >0.578947</td>\n",
       "      <td id=\"T_efc16_row1_col3\" class=\"data row1 col3\" >0.577664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efc16_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_efc16_row2_col0\" class=\"data row2 col0\" >0.554557</td>\n",
       "      <td id=\"T_efc16_row2_col1\" class=\"data row2 col1\" >0.508344</td>\n",
       "      <td id=\"T_efc16_row2_col2\" class=\"data row2 col2\" >0.509628</td>\n",
       "      <td id=\"T_efc16_row2_col3\" class=\"data row2 col3\" >0.507060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162e92028c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGG_FUNC = ['min','max','sum','average']\n",
    "\n",
    "all_aggregate_result = []\n",
    "for func in AGG_FUNC:\n",
    "  oclar_w2v = [sentence2vectorSum(i, w2v_oclar, aggregate=func) for i in df['clean']]\n",
    "  oclar_w2v = pd.DataFrame(oclar_w2v).drop(100, axis=1)\n",
    "\n",
    "  X = oclar_w2v\n",
    "  y = df['category_encoded']\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "  result = baseModelOnly(X_train,X_test,y_train,y_test, includeNB=False)\n",
    "  \"\"\"\n",
    "  Ntar jadi nya gini:\n",
    "  [[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb]]\n",
    "  setiap list itu buat satu aggregate function & setiap list itu dibuat perkolom\n",
    "  \"\"\"\n",
    "  all_aggregate_result.append(result)\n",
    "\n",
    "\n",
    "OCLAR_W2V_FINAL_RESULT = pd.DataFrame({AGG_FUNC[i]: all_aggregate_result[i] for i in range(len(AGG_FUNC))})\n",
    "OCLAR_W2V_FINAL_RESULT.index = ['Logreg','SVM','Decision Tree']\n",
    "OCLAR_W2V_FINAL_RESULT.style.background_gradient(cmap ='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBFYLFCP16zk"
   },
   "source": [
    "# HARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "R_YAkjFy1_Q7",
    "outputId": "71c44f31-67e5-4d4f-e780-57944f5a7e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Label : 4\n",
      "105618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“ممتاز”. النظافة والطاقم متعاون.</td>\n",
       "      <td>2</td>\n",
       "      <td>متز نظف طقم تعا</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...</td>\n",
       "      <td>5</td>\n",
       "      <td>استثنائي سهل عمل اشئ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...</td>\n",
       "      <td>5</td>\n",
       "      <td>استثنائي نصح أختيار اسي اخص غرف رقم نوع ارض</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...</td>\n",
       "      <td>1</td>\n",
       "      <td>غرب قيم ندق كخمس نجم شي سحق نجم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...</td>\n",
       "      <td>4</td>\n",
       "      <td>جيد جمل هاديء شي جيد نظف بس حوض سبح عمل هذي فت...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0                  “ممتاز”. النظافة والطاقم متعاون.        2   \n",
       "1  استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...       5   \n",
       "2  استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...       5   \n",
       "3  “استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...       1   \n",
       "4  جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...       4   \n",
       "\n",
       "                                               clean  category_encoded  \n",
       "0                                    متز نظف طقم تعا                 1  \n",
       "1                               استثنائي سهل عمل اشئ                 4  \n",
       "2        استثنائي نصح أختيار اسي اخص غرف رقم نوع ارض                 4  \n",
       "3                    غرب قيم ندق كخمس نجم شي سحق نجم                 0  \n",
       "4  جيد جمل هاديء شي جيد نظف بس حوض سبح عمل هذي فت...                 3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HARD_CLEAN.csv')\n",
    "df = df.dropna()\n",
    "df['category_encoded'] = df['rating']-1\n",
    "\n",
    "print(f\"Jumlah Label : {len(df['rating'].unique())}\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hFH-E_t626Al"
   },
   "outputs": [],
   "source": [
    "X = df['clean']\n",
    "y = df['category_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "RIuvpoeqQxPg",
    "outputId": "6875ab29-6f29-488f-a054-df35d9aa0cce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_da027_row0_col0, #T_da027_row0_col1, #T_da027_row3_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da027_row1_col0 {\n",
       "  background-color: #147e3a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da027_row1_col1 {\n",
       "  background-color: #1f8742;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da027_row2_col0, #T_da027_row2_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da027_row3_col0 {\n",
       "  background-color: #e9f7e5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_da027_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >TFIDF</th>\n",
       "      <th class=\"col_heading level0 col1\" >CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_da027_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_da027_row0_col0\" class=\"data row0 col0\" >0.707205</td>\n",
       "      <td id=\"T_da027_row0_col1\" class=\"data row0 col1\" >0.693382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da027_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_da027_row1_col0\" class=\"data row1 col0\" >0.689689</td>\n",
       "      <td id=\"T_da027_row1_col1\" class=\"data row1 col1\" >0.675866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da027_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_da027_row2_col0\" class=\"data row2 col0\" >0.618775</td>\n",
       "      <td id=\"T_da027_row2_col1\" class=\"data row2 col1\" >0.618728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da027_level0_row3\" class=\"row_heading level0 row3\" >NB</th>\n",
       "      <td id=\"T_da027_row3_col0\" class=\"data row3 col0\" >0.627438</td>\n",
       "      <td id=\"T_da027_row3_col1\" class=\"data row3 col1\" >0.693145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162e8fb8070>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_idf = tfidf.fit_transform(X_train)\n",
    "X_test_idf = tfidf.transform(X_test)\n",
    "\n",
    "#count vectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "tfidf_clf = baseModelOnly(X_train_idf,X_test_idf,y_train,y_test)\n",
    "cv_clf = baseModelOnly(X_train_cv,X_test_cv,y_train,y_test)\n",
    "\n",
    "hard_base_model_result = pd.DataFrame({'TFIDF':tfidf_clf,'CV':cv_clf})\n",
    "hard_base_model_result.index = ['Logreg','SVM','Decision Tree','NB']\n",
    "hard_base_model_result.style.background_gradient(cmap ='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBMWwUlJ6U-Q"
   },
   "source": [
    "## HARD word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O4dlhGIgPBs",
    "outputId": "e7d34b14-1cb4-4721-99af-4afcc7af436a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LEN : 395\n"
     ]
    }
   ],
   "source": [
    "hard_corpus = make_corpus(df.clean)\n",
    "max_len = max([len(sentence) for sentence in hard_corpus])\n",
    "print('MAX LEN : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9Cm37IMgSfb",
    "outputId": "8b70734f-bcda-46f9-dcb2-ebc5d6e2e3d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17203318, 52493160)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_hard = Word2Vec(min_count=10,window=15,sample=6e-5,alpha=0.03,min_alpha=0.0007,negative=25)\n",
    "w2v_hard.build_vocab(hard_corpus, progress_per=10000)\n",
    "w2v_hard.train(hard_corpus, total_examples=w2v_hard.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2ixl-bRF7yt"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_18841_row0_col0, #T_18841_row0_col1, #T_18841_row0_col2, #T_18841_row0_col3 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_18841_row1_col0 {\n",
       "  background-color: #9bd696;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_18841_row1_col1 {\n",
       "  background-color: #107a37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_18841_row1_col2 {\n",
       "  background-color: #62bb6d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_18841_row1_col3 {\n",
       "  background-color: #005622;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_18841_row2_col0, #T_18841_row2_col1, #T_18841_row2_col2, #T_18841_row2_col3 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_18841_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >min</th>\n",
       "      <th class=\"col_heading level0 col1\" >max</th>\n",
       "      <th class=\"col_heading level0 col2\" >sum</th>\n",
       "      <th class=\"col_heading level0 col3\" >average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_18841_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_18841_row0_col0\" class=\"data row0 col0\" >0.593496</td>\n",
       "      <td id=\"T_18841_row0_col1\" class=\"data row0 col1\" >0.576359</td>\n",
       "      <td id=\"T_18841_row0_col2\" class=\"data row0 col2\" >0.578536</td>\n",
       "      <td id=\"T_18841_row0_col3\" class=\"data row0 col3\" >0.653475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18841_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_18841_row1_col0\" class=\"data row1 col0\" >0.559884</td>\n",
       "      <td id=\"T_18841_row1_col1\" class=\"data row1 col1\" >0.567364</td>\n",
       "      <td id=\"T_18841_row1_col2\" class=\"data row1 col2\" >0.551979</td>\n",
       "      <td id=\"T_18841_row1_col3\" class=\"data row1 col3\" >0.645332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18841_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_18841_row2_col0\" class=\"data row2 col0\" >0.538014</td>\n",
       "      <td id=\"T_18841_row2_col1\" class=\"data row2 col1\" >0.526463</td>\n",
       "      <td id=\"T_18841_row2_col2\" class=\"data row2 col2\" >0.520025</td>\n",
       "      <td id=\"T_18841_row2_col3\" class=\"data row2 col3\" >0.512829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162e8f396c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_aggregate_result = []\n",
    "for func in AGG_FUNC:\n",
    "  hard_w2v = [sentence2vectorSum(i, w2v_hard, aggregate=func) for i in df['clean']]\n",
    "  hard_w2v = pd.DataFrame(hard_w2v).drop(100, axis=1)\n",
    "\n",
    "  X = hard_w2v\n",
    "  y = df['category_encoded']\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "  result = baseModelOnly(X_train,X_test,y_train,y_test, includeNB=False)\n",
    "  \"\"\"\n",
    "  Ntar jadi nya gini:\n",
    "  [[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb]]\n",
    "  setiap list itu buat satu aggregate function & setiap list itu dibuat perkolom\n",
    "  \"\"\"\n",
    "  all_aggregate_result.append(result)\n",
    "\n",
    "\n",
    "HARD_W2V_FINAL_RESULT = pd.DataFrame({AGG_FUNC[i]: all_aggregate_result[i] for i in range(len(AGG_FUNC))})\n",
    "HARD_W2V_FINAL_RESULT.index = ['Logreg','SVM','Decision Tree']\n",
    "HARD_W2V_FINAL_RESULT.style.background_gradient(cmap ='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyePF-7l3l26"
   },
   "source": [
    "# SANAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E3Rvv3-P3mVh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Label : 7\n",
      "45500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بيروت: «الخليج» وحدها القدس تتصدر غلاف العدد 1...</td>\n",
       "      <td>culture</td>\n",
       "      <td>يرو خلج وحد قدس صدر غلف جلة درس فلسطينية كتب ا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هل هناك قصة جديدة إماراتية؟ ما الإضافات التي ت...</td>\n",
       "      <td>culture</td>\n",
       "      <td>قصة جدد اماراتية اضف سجل قصة لمح الخ سئل بتت ف...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>موقف مقدّر ذلك الذي اتخذه اتحاد كتاب وأدباء ال...</td>\n",
       "      <td>culture</td>\n",
       "      <td>قدر تحد كتب أدباء امر نشر صحف شرح حدث شهد نطق ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>القاهرة - \"الخليج\":التقى وزير الثقافة المصري د...</td>\n",
       "      <td>culture</td>\n",
       "      <td>قهر خليجالتقى وزر ثقف صري جبر عصفور وزر ثقف لن...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مسقط: «الخليج» عائشة الفزاري واسمها المستعار «...</td>\n",
       "      <td>culture</td>\n",
       "      <td>سقط خلج عئش فزر وسم عار خفا روح شعر عمن صيل كت...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category  \\\n",
       "0  بيروت: «الخليج» وحدها القدس تتصدر غلاف العدد 1...  culture   \n",
       "1  هل هناك قصة جديدة إماراتية؟ ما الإضافات التي ت...  culture   \n",
       "2  موقف مقدّر ذلك الذي اتخذه اتحاد كتاب وأدباء ال...  culture   \n",
       "3  القاهرة - \"الخليج\":التقى وزير الثقافة المصري د...  culture   \n",
       "4  مسقط: «الخليج» عائشة الفزاري واسمها المستعار «...  culture   \n",
       "\n",
       "                                               clean  category_encoded  \n",
       "0  يرو خلج وحد قدس صدر غلف جلة درس فلسطينية كتب ا...                 0  \n",
       "1  قصة جدد اماراتية اضف سجل قصة لمح الخ سئل بتت ف...                 0  \n",
       "2  قدر تحد كتب أدباء امر نشر صحف شرح حدث شهد نطق ...                 0  \n",
       "3  قهر خليجالتقى وزر ثقف صري جبر عصفور وزر ثقف لن...                 0  \n",
       "4  سقط خلج عئش فزر وسم عار خفا روح شعر عمن صيل كت...                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"SANAD_CLEAN.csv\")\n",
    "df['category_encoded'] = df['category'].map({'culture':0,'finance':1,'medical':2,'politics':3,'religion':4,'sports':5,'tech':6})\n",
    "\n",
    "print(f\"Jumlah Label : {len(df['category'].unique())}\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MYGtz__-4jrl"
   },
   "outputs": [],
   "source": [
    "X = df['clean']\n",
    "y = df['category_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "W3WRtAkH5Tx4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9a3ee_row0_col0, #T_9a3ee_row1_col1 {\n",
       "  background-color: #005120;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a3ee_row0_col1, #T_9a3ee_row1_col0 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a3ee_row2_col0, #T_9a3ee_row2_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a3ee_row3_col0 {\n",
       "  background-color: #208843;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a3ee_row3_col1 {\n",
       "  background-color: #0c7735;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9a3ee_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >TFIDF</th>\n",
       "      <th class=\"col_heading level0 col1\" >CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9a3ee_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_9a3ee_row0_col0\" class=\"data row0 col0\" >0.970879</td>\n",
       "      <td id=\"T_9a3ee_row0_col1\" class=\"data row0 col1\" >0.965714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a3ee_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_9a3ee_row1_col0\" class=\"data row1 col0\" >0.975055</td>\n",
       "      <td id=\"T_9a3ee_row1_col1\" class=\"data row1 col1\" >0.961758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a3ee_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_9a3ee_row2_col0\" class=\"data row2 col0\" >0.872418</td>\n",
       "      <td id=\"T_9a3ee_row2_col1\" class=\"data row2 col1\" >0.870549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a3ee_level0_row3\" class=\"row_heading level0 row3\" >NB</th>\n",
       "      <td id=\"T_9a3ee_row3_col0\" class=\"data row3 col0\" >0.950220</td>\n",
       "      <td id=\"T_9a3ee_row3_col1\" class=\"data row3 col1\" >0.949560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162e8daca60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_idf = tfidf.fit_transform(X_train)\n",
    "X_test_idf = tfidf.transform(X_test)\n",
    "\n",
    "#count vectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "tfidf_clf = baseModelOnly(X_train_idf,X_test_idf,y_train,y_test)\n",
    "cv_clf = baseModelOnly(X_train_cv,X_test_cv,y_train,y_test)\n",
    "\n",
    "sanad_base_model_result = pd.DataFrame({'TFIDF':tfidf_clf,'CV':cv_clf})\n",
    "sanad_base_model_result.index = ['Logreg','SVM','Decision Tree','NB']\n",
    "sanad_base_model_result.style.background_gradient(cmap ='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANAD word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LEN : 3816\n"
     ]
    }
   ],
   "source": [
    "sanad_corpus = make_corpus(df.clean)\n",
    "max_len = max([len(sentence) for sentence in sanad_corpus])\n",
    "print('MAX LEN : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40min 24s\n",
      "Wall time: 16min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(163561258, 339972570)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_sanad = Word2Vec(min_count=10,window=15,sample=6e-5,alpha=0.03,min_alpha=0.0007,negative=25)\n",
    "w2v_sanad.build_vocab(sanad_corpus, progress_per=10000)\n",
    "w2v_sanad.train(sanad_corpus, total_examples=w2v_sanad.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 9min 1s\n",
      "Wall time: 1h 12min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4ba8e_row0_col0, #T_4ba8e_row0_col1, #T_4ba8e_row0_col2, #T_4ba8e_row0_col3 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ba8e_row1_col0 {\n",
       "  background-color: #2c944c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ba8e_row1_col1 {\n",
       "  background-color: #1d8640;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ba8e_row1_col2, #T_4ba8e_row2_col0, #T_4ba8e_row2_col1, #T_4ba8e_row2_col3 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4ba8e_row1_col3 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ba8e_row2_col2 {\n",
       "  background-color: #e7f6e2;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4ba8e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >min</th>\n",
       "      <th class=\"col_heading level0 col1\" >max</th>\n",
       "      <th class=\"col_heading level0 col2\" >sum</th>\n",
       "      <th class=\"col_heading level0 col3\" >average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4ba8e_level0_row0\" class=\"row_heading level0 row0\" >Logreg</th>\n",
       "      <td id=\"T_4ba8e_row0_col0\" class=\"data row0 col0\" >0.877912</td>\n",
       "      <td id=\"T_4ba8e_row0_col1\" class=\"data row0 col1\" >0.886703</td>\n",
       "      <td id=\"T_4ba8e_row0_col2\" class=\"data row0 col2\" >0.884945</td>\n",
       "      <td id=\"T_4ba8e_row0_col3\" class=\"data row0 col3\" >0.964505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ba8e_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_4ba8e_row1_col0\" class=\"data row1 col0\" >0.836923</td>\n",
       "      <td id=\"T_4ba8e_row1_col1\" class=\"data row1 col1\" >0.847912</td>\n",
       "      <td id=\"T_4ba8e_row1_col2\" class=\"data row1 col2\" >0.691429</td>\n",
       "      <td id=\"T_4ba8e_row1_col3\" class=\"data row1 col3\" >0.963516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ba8e_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_4ba8e_row2_col0\" class=\"data row2 col0\" >0.734396</td>\n",
       "      <td id=\"T_4ba8e_row2_col1\" class=\"data row2 col1\" >0.716264</td>\n",
       "      <td id=\"T_4ba8e_row2_col2\" class=\"data row2 col2\" >0.713736</td>\n",
       "      <td id=\"T_4ba8e_row2_col3\" class=\"data row2 col3\" >0.889451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24d392e3a00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "AGG_FUNC = ['min','max','sum','average']\n",
    "\n",
    "all_aggregate_result = []\n",
    "for func in AGG_FUNC:\n",
    "  sanad_w2v = [sentence2vectorSum(i, w2v_sanad, aggregate=func) for i in df['clean']]\n",
    "  sanad_w2v = pd.DataFrame(sanad_w2v)\n",
    "\n",
    "  X = sanad_w2v\n",
    "  y = df['category_encoded']\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "  result = baseModelOnly(X_train,X_test,y_train,y_test, includeNB=False)\n",
    "  \"\"\"\n",
    "  Ntar jadi nya gini:\n",
    "  [[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb],[logreg,svm,dt,nb]]\n",
    "  setiap list itu buat satu aggregate function & setiap list itu dibuat perkolom\n",
    "  \"\"\"\n",
    "  all_aggregate_result.append(result)\n",
    "\n",
    "\n",
    "SANAD_W2V_FINAL_RESULT = pd.DataFrame({AGG_FUNC[i]: all_aggregate_result[i] for i in range(len(AGG_FUNC))})\n",
    "SANAD_W2V_FINAL_RESULT.index = ['Logreg','SVM','Decision Tree']\n",
    "SANAD_W2V_FINAL_RESULT.style.background_gradient(cmap ='Greens')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
